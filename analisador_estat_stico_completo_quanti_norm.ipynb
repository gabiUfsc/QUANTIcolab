{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabiUfsc/QUANTIcolab/blob/main/analisador_estat_stico_completo_quanti_norm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "import unicodedata\n",
        "\n",
        "# =================================================================\n",
        "# 1. MAPEAMENTO DOS ARQUIVOS (NOMES EXATOS VERIFICADOS)\n",
        "# =================================================================\n",
        "GRUPOS = {\n",
        "    'Extrema Direita': [\n",
        "        'olavodcarvalho.txt',\n",
        "        'sergio_moro1_25.txt',\n",
        "        'RodConstantino1_25.txt',\n",
        "        'Nikole_1_25.txt',\n",
        "        'principe_1_25.txt'\n",
        "    ],\n",
        "    'Centro': [\n",
        "        'elio_gaspari.txt',\n",
        "        'celso_rochaDebarros.txt',\n",
        "        'Josias de Souza.txt',\n",
        "        'reinaldo_1_25.txt',\n",
        "        'joel_pinheiro.txt'\n",
        "    ],\n",
        "    'Esquerda': [\n",
        "        'jesse_souza.txt',\n",
        "        'attuch_1_25.txt',\n",
        "        'xicoSa_1_25.txt',\n",
        "        'luisCPinto.txt',\n",
        "        'pauloMLeite1_25.txt'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# =================================================================\n",
        "# 2. OS 30 LEXEMAS (EIXOS SEMÂNTICOS)\n",
        "# =================================================================\n",
        "LEXEMAS = {\n",
        "    'ALIADO/ALIANÇA': r'\\b(aliad[oa][s]?|alian[cç][a-z]*|aliar)\\b',\n",
        "    'AMEAÇAR/AMEAÇA': r'\\bamea[cç][a-z]*\\b',\n",
        "    'ARMA/ARMAMENTO': r'\\barm(as?|inha|amento|amentista)\\b',\n",
        "    'ATACAR/ATAQUE': r'\\b(atac[a-z]*|ataqu[ei][a-z]*)\\b',\n",
        "    'AVANÇAR/AVANÇO': r'\\bavan[cç][a-z]*\\b',\n",
        "    'BLOQUEAR/BLOQUEIO': r'\\bbloque[a-z]*\\b',\n",
        "    'CAMPANHA': r'\\bcampanh[a-z]*\\b',\n",
        "    'COMANDAR/COMANDO': r'\\bcomand[a-z]*\\b',\n",
        "    'COMBATER/COMBATE': r'\\bcombat[ei][a-z]*\\b',\n",
        "    'DEFENDER/DEFESA': r'\\b(defend[a-z]*|defes[a-z]*)\\b',\n",
        "    'DERROTAR/DERROTA': r'\\bderrot[a-z]*\\b',\n",
        "    'DESTRUIR/DESTRUIÇÃO': r'\\bdestr[ui][a-z]*\\b',\n",
        "    'ESTRATÉGIA': r'\\bestrat.g[a-z]*\\b',\n",
        "    'GUERRA': r'\\bguerr[a-z]*\\b',\n",
        "    'INIMIGO': r'\\b(inimig[oa][s]?|inimiz[a-z]*)\\b',\n",
        "    'INVADIR/INVASÃO': r'\\b(invad[a-z]*|invas[a-z]*)\\b',\n",
        "    'LUTAR/LUTA': r'\\b(lut[as]|lutou|lutaram|lutando)\\b',\n",
        "    'MANOBRAR/MANOBRA': r'\\bmanobr[a-z]*\\b',\n",
        "    'MISSÃO': r'\\bmiss.o\\b|\\bmiss.es\\b',\n",
        "    'MOBILIZAR/MOBILIZAÇÃO': r'\\bmobiliz[a-z]*\\b',\n",
        "    'MUNIÇÃO': r'\\bmuni[cç][a-z]*\\b',\n",
        "    'PROTEGER/PROTEÇÃO': r'\\bprote[cg][a-z]*\\b',\n",
        "    'PUNIÇÃO/PUNIR': r'\\bpuni[cç][a-z]*\\b',\n",
        "    'RECUAR/RECUO': r'\\brecu[a-z]*\\b',\n",
        "    'RESISTIR/RESISTÊNCIA': r'\\bresist[a-z]*\\b',\n",
        "    'SALVAR/SALVAÇÃO': r'\\bsalv[a-z]*\\b',\n",
        "    'SANÇÃO': r'\\bsan[cç][a-z]*\\b',\n",
        "    'TIRO/ATIRAR': r'\\b(tiro[s]?|dispar[a-z]*|atir[a-z]*)\\b',\n",
        "    'VENCER/VENCEDOR': r'\\bvenc[a-z]*\\b',\n",
        "    'VITÓRIA': r'\\bvit.r[a-z]*\\b'\n",
        "}\n",
        "\n",
        "# =================================================================\n",
        "# 3. MOTOR DE CÁLCULO\n",
        "# =================================================================\n",
        "\n",
        "dados_detalhados = []\n",
        "\n",
        "print(\">>> INICIANDO CÁLCULOS COMPLETOS (QUANTI + NORM)...\")\n",
        "\n",
        "for grupo, arquivos in GRUPOS.items():\n",
        "    for arquivo in arquivos:\n",
        "        nome_limpo = arquivo.replace('.txt', '').replace('_', ' ').replace('1 25', '').title()\n",
        "\n",
        "        if not os.path.exists(arquivo):\n",
        "            print(f\"[ERRO] Arquivo ausente: {arquivo}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(arquivo, 'r', encoding='utf-8') as f:\n",
        "                texto = f.read()\n",
        "        except:\n",
        "            with open(arquivo, 'r', encoding='latin-1') as f:\n",
        "                texto = f.read()\n",
        "\n",
        "        # 1. Contagem Total de Palavras (N)\n",
        "        # Removemos pontuação básica para contar palavras reais\n",
        "        tokens = re.findall(r'\\b\\w+\\b', texto.lower())\n",
        "        total_palavras_autor = len(tokens)\n",
        "\n",
        "        if total_palavras_autor == 0:\n",
        "            print(f\"[AVISO] Arquivo vazio: {arquivo}\")\n",
        "            continue\n",
        "\n",
        "        # 2. Busca de Lexemas\n",
        "        for categoria, regex in LEXEMAS.items():\n",
        "            ocorrencias = len(re.findall(regex, texto, re.IGNORECASE))\n",
        "\n",
        "            if ocorrencias > 0:\n",
        "                dados_detalhados.append({\n",
        "                    'Ideologia': grupo,\n",
        "                    'Autor': nome_limpo,\n",
        "                    'Lexema': categoria,\n",
        "                    'Hits_Absolutos': ocorrencias,\n",
        "                    'Total_Palavras_Autor': total_palavras_autor\n",
        "                })\n",
        "\n",
        "# =================================================================\n",
        "# 4. GERAÇÃO DAS TABELAS ESTATÍSTICAS\n",
        "# =================================================================\n",
        "\n",
        "df = pd.DataFrame(dados_detalhados)\n",
        "\n",
        "if not df.empty:\n",
        "    # --- CÁLCULO 1: Agrupamento por Ideologia e Lexema ---\n",
        "    # Somamos os hits de todos os autores do grupo para cada lexema\n",
        "    df_ideologia = df.groupby(['Ideologia', 'Lexema']).agg({\n",
        "        'Hits_Absolutos': 'sum',\n",
        "        'Total_Palavras_Autor': 'sum' # Cuidado: aqui somamos o total de palavras repetido para cada lexema, corrigiremos abaixo\n",
        "    }).reset_index()\n",
        "\n",
        "    # Correção do Total de Palavras por Grupo (Para Normalização Correta)\n",
        "    # Primeiro calculamos o total real de palavras de cada grupo (somando 1x por autor)\n",
        "    df_unicos = df[['Ideologia', 'Autor', 'Total_Palavras_Autor']].drop_duplicates()\n",
        "    total_palavras_grupo = df_unicos.groupby('Ideologia')['Total_Palavras_Autor'].sum().to_dict()\n",
        "\n",
        "    # --- CÁLCULO 2: Métricas Finais (Relativa e Normalizada) ---\n",
        "    def calcular_metricas(row):\n",
        "        n_total = total_palavras_grupo[row['Ideologia']]\n",
        "        hits = row['Hits_Absolutos']\n",
        "\n",
        "        # Frequência Relativa (%)\n",
        "        freq_relativa = (hits / n_total) * 100\n",
        "\n",
        "        # Frequência Normalizada (por 10.000 palavras)\n",
        "        freq_norm = (hits / n_total) * 10000\n",
        "\n",
        "        return pd.Series([n_total, freq_relativa, freq_norm])\n",
        "\n",
        "    df_ideologia[['Total_Palavras_Grupo', 'Freq_Relativa_%', 'Freq_Norm_10k']] = df_ideologia.apply(calcular_metricas, axis=1)\n",
        "\n",
        "    # Arredondamento para estética\n",
        "    df_ideologia['Freq_Relativa_%'] = df_ideologia['Freq_Relativa_%'].round(4)\n",
        "    df_ideologia['Freq_Norm_10k'] = df_ideologia['Freq_Norm_10k'].round(2)\n",
        "\n",
        "    # --- EXPORTAÇÃO ---\n",
        "\n",
        "    # 1. Tabela Matriz (Ideologia x Lexema - Normalizada)\n",
        "    matriz_norm = df_ideologia.pivot(index='Lexema', columns='Ideologia', values='Freq_Norm_10k').fillna(0)\n",
        "    matriz_norm.to_csv('FINAL_Matriz_Normalizada_10k.csv', encoding='utf-8-sig')\n",
        "\n",
        "    # 2. Relatório Completo (Lista Longa)\n",
        "    df_ideologia.to_csv('FINAL_Relatorio_Estatistico_Completo.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ESTATÍSTICAS FINAIS GERADAS COM SUCESSO\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Total de palavras analisadas por grupo:\")\n",
        "    for grupo, total in total_palavras_grupo.items():\n",
        "        print(f\"  - {grupo}: {total} palavras\")\n",
        "\n",
        "    print(\"\\n>>> ARQUIVOS CRIADOS NA PASTA:\")\n",
        "    print(\"1. 'FINAL_Matriz_Normalizada_10k.csv'\")\n",
        "    print(\"   (Esta é a tabela pronta para fazer o GRÁFICO COMPARATIVO)\")\n",
        "    print(\"2. 'FINAL_Relatorio_Estatistico_Completo.csv'\")\n",
        "    print(\"   (Contém os cálculos de % e números absolutos para citação)\")\n",
        "\n",
        "else:\n",
        "    print(\"Nenhum dado encontrado. Verifique os arquivos.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> INICIANDO CÁLCULOS COMPLETOS (QUANTI + NORM)...\n",
            "\n",
            "============================================================\n",
            "ESTATÍSTICAS FINAIS GERADAS COM SUCESSO\n",
            "============================================================\n",
            "Total de palavras analisadas por grupo:\n",
            "  - Centro: 70274 palavras\n",
            "  - Esquerda: 70434 palavras\n",
            "  - Extrema Direita: 87326 palavras\n",
            "\n",
            ">>> ARQUIVOS CRIADOS NA PASTA:\n",
            "1. 'FINAL_Matriz_Normalizada_10k.csv'\n",
            "   (Esta é a tabela pronta para fazer o GRÁFICO COMPARATIVO)\n",
            "2. 'FINAL_Relatorio_Estatistico_Completo.csv'\n",
            "   (Contém os cálculos de % e números absolutos para citação)\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjFtOkIqSG8r",
        "outputId": "3864b5a7-ae3e-4330-cbf0-08f8df06c385"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}